"""Stock data fetching and preprocessing utilities."""

import yfinance as yf
import numpy as np
import pandas as pd
from typing import Optional
from sklearn.preprocessing import MinMaxScaler
from datetime import datetime, timedelta

class StockDataProcessor:
    """Fetch, enrich, and format stock data for model inputs."""
    
    def __init__(self, ticker: str = "AAPL"):
        """Initialize the processor with a ticker symbol."""
        self.ticker = ticker
        self.data: Optional[pd.DataFrame] = None
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.target_scaler = MinMaxScaler(feature_range=(0, 1)) # Scaler just for the target value
        
    def fetch_data(self, years: int = 5) -> pd.DataFrame:
        """Fetch historical stock data for the configured ticker."""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=years * 365)
        
        stock = yf.Ticker(self.ticker)
        df = stock.history(start=start_date, end=end_date)
        
        if df.empty:
            raise ValueError(f"No data found for ticker {self.ticker}")
        
        self.data = df
        return df

    def add_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """Add SMA, RSI, and MACD features to a copy of the data."""
        df = df.copy()
        
        # Simple Moving Average (SMA)
        df['SMA_20'] = df['Close'].rolling(window=20).mean()
        df['SMA_50'] = df['Close'].rolling(window=50).mean()
        
        # Relative Strength Index (RSI)
        delta = df['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD (Moving Average Convergence Divergence)
        exp1 = df['Close'].ewm(span=12, adjust=False).mean()
        exp2 = df['Close'].ewm(span=26, adjust=False).mean()
        df['MACD'] = exp1 - exp2
        df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
        
        # Fill NaN values generated by indicators
        df.bfill(inplace=True)
        df.ffill(inplace=True) # Fallback
        
        return df

    def prepare_for_lstm(self, df: pd.DataFrame, sequence_length: int = 60, target_col: str = 'Close'):
        """Prepare sequences for LSTM training and return scaled splits."""
        # Enrichment step
        data = self.add_technical_indicators(df)
        
        # Define features to use
        feature_cols = ['Close', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Signal_Line']
        
        # Save feature columns for later use
        self.feature_cols = feature_cols
        
        # SPLIT DATA FIRST (80/20) to prevent leakage
        split_idx = int(len(data) * 0.8)
        train_df = data.iloc[:split_idx]
        test_df = data.iloc[split_idx:]
        
        # FIT scalers ONLY on training data
        self.scaler.fit(train_df[feature_cols].values)
        target_values = train_df[target_col].values.reshape(-1, 1)
        self.target_scaler.fit(target_values)
        
        # Transform both sets using the Training scaler
        train_scaled = self.scaler.transform(train_df[feature_cols].values)
        test_scaled = self.scaler.transform(test_df[feature_cols].values)
        
        # Helper to create sequences
        def create_sequences(dataset):
            """Create sliding window sequences for features and target."""
            X, y = [], []
            target_idx = feature_cols.index(target_col)
            for i in range(sequence_length, len(dataset)):
                X.append(dataset[i - sequence_length:i, :]) # All features
                y.append(dataset[i, target_idx]) # Only target
            return np.array(X), np.array(y)
            
        # Create sequences for both sets
        X_train, y_train = create_sequences(train_scaled)
        
        # For Test set, we need to concatenate the last 'sequence_length' from train 
        # to ensure we don't lose the first few test points
        # But for strict separation, standard practice is just processing test_scaled
        X_test, y_test = create_sequences(test_scaled)
        
        # Reshape is automatic since X is [samples, seq_len, features]
        
        return X_train, y_train, X_test, y_test, self.target_scaler, data

    def get_latest_sequence(self, df: pd.DataFrame, sequence_length: int = 60, target_col: str = 'Close'):
        """Return the most recent scaled feature window for inference."""
        # Ensure indicators exist
        if 'RSI' not in df.columns:
            df = self.add_technical_indicators(df)
            
        feature_cols = ['Close', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Signal_Line']
        dataset = df[feature_cols].values[-sequence_length:]
        
        scaled = self.scaler.transform(dataset)
        return np.reshape(scaled, (1, sequence_length, len(feature_cols)))

    def prepare_for_classification(self, df: pd.DataFrame, target_col: str = 'Close'):
        """Prepare features/labels for a next-day direction classifier."""
        df = df.copy()
        
        # Enrichment
        if 'RSI' not in df.columns:
            df = self.add_technical_indicators(df)
            
        # Create Target: 1 if Close(t+1) > Close(t), else 0
        df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
        
        # Drop the last row because it has no future target
        df = df.iloc[:-1]
        
        feature_cols = ['Close', 'SMA_20', 'SMA_50', 'RSI', 'MACD', 'Signal_Line']
        self.feature_cols = feature_cols
        
        # Split Data (80/20) - Time Series split (no shuffling)
        split_idx = int(len(df) * 0.8)
        train_df = df.iloc[:split_idx]
        test_df = df.iloc[split_idx:]
        
        X_train = train_df[feature_cols].values
        y_train = train_df['Target'].values
        
        X_test = test_df[feature_cols].values
        y_test = test_df['Target'].values
        
        return X_train, y_train, X_test, y_test, feature_cols

# Helper functions for backward compatibility or simple usage
def fetch_stock_data(ticker="AAPL", years=5):
    """Fetch historical data for a ticker using the processor."""
    processor = StockDataProcessor(ticker)
    return processor.fetch_data(years)

def prepare_data_for_lstm(df, sequence_length=60):
    """Prepare LSTM-ready sequences with default processor settings."""
    processor = StockDataProcessor()
    return processor.prepare_for_lstm(df, sequence_length)

def get_latest_sequence(df, scaler, sequence_length=60):
    """Return the latest scaled window using the provided scaler."""
    # Note: This helper requires the passed scaler, ignoring the processor's internal one
    # to maintain compatibility with existing app logic that passes scaler around
    processor = StockDataProcessor()
    processor.scaler = scaler 
    return processor.get_latest_sequence(df, sequence_length)
